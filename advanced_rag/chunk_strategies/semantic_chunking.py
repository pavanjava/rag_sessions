from chonkie import SemanticChunker

from doc_reader_util import get_documents

# Basic initialization with default parameters
chunker = SemanticChunker(
    embedding_model="minishlab/potion-base-8M",  # Default model
    threshold=0.5,                               # Similarity threshold (0-1) or (1-100) or "auto"
    chunk_size=512,                              # Maximum tokens per chunk
    min_sentences=1,                             # Initial sentences per chunk
    mode="window",                               # Mode for grouping sentences, either “cumulative” or “window”
    similarity_window=10,                        # Number of sentences to consider for similarity threshold calculation

)

docs = get_documents()

for doc in docs:
    chunks = chunker.chunk(doc.text)

    for chunk in chunks:
        print(f"Chunk text: {chunk.text}")
        print(f"Token count: {chunk.token_count}")
        print(f"Start index: {chunk.start_index}")
        print(f"End index: {chunk.end_index}")
